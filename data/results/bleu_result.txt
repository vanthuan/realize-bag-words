train:499 sentences
=> Optimizing Lambda: [0.1,0.2,-0.1]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10029 / 12293 = 0.8158
BLEU_precision(3) = 8494 / 11768 = 0.7218
BLEU_precision(4) = 7190 / 11244 = 0.6395
BLEU_precision = 0.7833
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7833

 
	========================================================
train:499 sentences
=> Optimizing Lambda: [0.1,0.2,-0.1]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10029 / 12293 = 0.8158
BLEU_precision(3) = 8494 / 11768 = 0.7218
BLEU_precision(4) = 7190 / 11244 = 0.6395
BLEU_precision = 0.7833
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7833

 
	========================================================
train:499 sentences
=> Optimizing Lambda: [-0.05,-0.6577977590753961,0.46016061237234096]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9317 / 12293 = 0.7579
BLEU_precision(3) = 7376 / 11768 = 0.6268
BLEU_precision(4) = 5746 / 11244 = 0.5110
BLEU_precision = 0.7019
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7019

 
	========================================================
train:499 sentences
=> Optimizing Lambda: [-0.05,-0.6577977590753961,0.46016061237234096]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9317 / 12293 = 0.7579
BLEU_precision(3) = 7376 / 11768 = 0.6268
BLEU_precision(4) = 5746 / 11244 = 0.5110
BLEU_precision = 0.7019
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7019

 
	========================================================
train:499 sentences
=> Optimizing Lambda: [-0.21052430917292875,0.981831267676273,8693020.75161818]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9327 / 12293 = 0.7587
BLEU_precision(3) = 7382 / 11768 = 0.6273
BLEU_precision(4) = 5759 / 11244 = 0.5122
BLEU_precision = 0.7027
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7027

 
	========================================================
train:499 sentences
=> Optimizing Lambda: [-0.21052430917292875,0.981831267676273,8693020.75161818]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9327 / 12293 = 0.7587
BLEU_precision(3) = 7382 / 11768 = 0.6273
BLEU_precision(4) = 5759 / 11244 = 0.5122
BLEU_precision = 0.7027
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7027

 
	========================================================
train:100 sentences
=> Optimizing Lambda: [3300.6444589634457,7929434.30054603,-27264.54821554008]
test:50 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 1429 / 1429 = 1.0000
BLEU_precision(2) = 1024 / 1379 = 0.7426
BLEU_precision(3) = 789 / 1329 = 0.5937
BLEU_precision(4) = 602 / 1279 = 0.4707
BLEU_precision = 0.6749
Length of candidate corpus = 1429
Effective length of reference corpus = 1429
BLEU_BP = 1.0000
  => BLEU = 0.6749

 
	========================================================
train:100 sentences
=> Optimizing Lambda: [3300.6444589634457,7929434.30054603,-27264.54821554008]
test:50 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 1429 / 1429 = 1.0000
BLEU_precision(2) = 1024 / 1379 = 0.7426
BLEU_precision(3) = 789 / 1329 = 0.5937
BLEU_precision(4) = 602 / 1279 = 0.4707
BLEU_precision = 0.6749
Length of candidate corpus = 1429
Effective length of reference corpus = 1429
BLEU_BP = 1.0000
  => BLEU = 0.6749

 
	========================================================
train:500 sentences
=> Optimizing Lambda: [-1226.468439333556,3665.2324727412088,3143.6345487968056]
test:400 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 10179 / 10179 = 1.0000
BLEU_precision(2) = 6771 / 9779 = 0.6924
BLEU_precision(3) = 4973 / 9379 = 0.5302
BLEU_precision(4) = 3485 / 8980 = 0.3881
BLEU_precision = 0.6144
Length of candidate corpus = 10179
Effective length of reference corpus = 10179
BLEU_BP = 1.0000
  => BLEU = 0.6144

 
	========================================================
train:500 sentences
=> Optimizing Lambda: [-0.13287646509006532,-0.6577977590753961,-0.44235450692001854]
test:400 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 10179 / 10179 = 1.0000
BLEU_precision(2) = 7458 / 9779 = 0.7627
BLEU_precision(3) = 5891 / 9379 = 0.6281
BLEU_precision(4) = 4595 / 8980 = 0.5117
BLEU_precision = 0.7036
Length of candidate corpus = 10179
Effective length of reference corpus = 10179
BLEU_BP = 1.0000
  => BLEU = 0.7036

 
	========================================================
train:1000 sentences
=> Optimizing Lambda: [-0.050006688033419906,-0.6577977590753961,-4.452980779849642E-5]
test:400 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 8414 / 8414 = 1.0000
BLEU_precision(2) = 5943 / 8014 = 0.7416
BLEU_precision(3) = 4535 / 7615 = 0.5955
BLEU_precision(4) = 3405 / 7218 = 0.4717
BLEU_precision = 0.6756
Length of candidate corpus = 8414
Effective length of reference corpus = 8414
BLEU_BP = 1.0000
  => BLEU = 0.6756

 
	========================================================
train:1000 sentences
=> Optimizing Lambda: [-0.05,-0.5713556223455967,0.05]
test:400 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 8414 / 8414 = 1.0000
BLEU_precision(2) = 5916 / 8014 = 0.7382
BLEU_precision(3) = 4527 / 7615 = 0.5945
BLEU_precision(4) = 3412 / 7218 = 0.4727
BLEU_precision = 0.6749
Length of candidate corpus = 8414
Effective length of reference corpus = 8414
BLEU_BP = 1.0000
  => BLEU = 0.6749

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [0.05,0.8593774528720801,-0.055347593582887704]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4202 / 5552 = 0.7568
BLEU_precision(3) = 3301 / 5352 = 0.6168
BLEU_precision(4) = 2534 / 5152 = 0.4918
BLEU_precision = 0.6922
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.6922

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [0.05,0.8593774528720801,-0.055347593582887704]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4202 / 5552 = 0.7568
BLEU_precision(3) = 3301 / 5352 = 0.6168
BLEU_precision(4) = 2534 / 5152 = 0.4918
BLEU_precision = 0.6922
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.6922

 
	========================================================
train:10 sentences
=> Optimizing Lambda: [-0.05,-0.05,-0.1]
test:2 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 42 / 42 = 1.0000
BLEU_precision(2) = 32 / 40 = 0.8000
BLEU_precision(3) = 25 / 38 = 0.6579
BLEU_precision(4) = 19 / 36 = 0.5278
BLEU_precision = 0.7260
Length of candidate corpus = 42
Effective length of reference corpus = 42
BLEU_BP = 1.0000
  => BLEU = 0.7260

 
	========================================================
train:10 sentences
=> Optimizing Lambda: [-3.341598746054889E-17,-0.05,0.04999999620769821]
test:2 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 42 / 42 = 1.0000
BLEU_precision(2) = 32 / 40 = 0.8000
BLEU_precision(3) = 25 / 38 = 0.6579
BLEU_precision(4) = 19 / 36 = 0.5278
BLEU_precision = 0.7260
Length of candidate corpus = 42
Effective length of reference corpus = 42
BLEU_BP = 1.0000
  => BLEU = 0.7260

 
	========================================================
train:10 sentences
=> Optimizing Lambda: [-3.341598746054889E-17,-0.05,0.04999999620769821]
test:2 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 42 / 42 = 1.0000
BLEU_precision(2) = 32 / 40 = 0.8000
BLEU_precision(3) = 25 / 38 = 0.6579
BLEU_precision(4) = 19 / 36 = 0.5278
BLEU_precision = 0.7260
Length of candidate corpus = 42
Effective length of reference corpus = 42
BLEU_BP = 1.0000
  => BLEU = 0.7260

 
	========================================================
train:10 sentences
=> Optimizing Lambda: [-3.341598746054889E-17,-0.05,0.04999999620769821]
test:2 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 42 / 42 = 1.0000
BLEU_precision(2) = 32 / 40 = 0.8000
BLEU_precision(3) = 25 / 38 = 0.6579
BLEU_precision(4) = 19 / 36 = 0.5278
BLEU_precision = 0.7260
Length of candidate corpus = 42
Effective length of reference corpus = 42
BLEU_BP = 1.0000
  => BLEU = 0.7260

 
	========================================================
train:10 sentences
=> Optimizing Lambda: [-3.341598746054889E-17,-0.05,0.04999999620769821]
test:2 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 42 / 42 = 1.0000
BLEU_precision(2) = 33 / 40 = 0.8250
BLEU_precision(3) = 28 / 38 = 0.7368
BLEU_precision(4) = 24 / 36 = 0.6667
BLEU_precision = 0.7979
Length of candidate corpus = 42
Effective length of reference corpus = 42
BLEU_BP = 1.0000
  => BLEU = 0.7979

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [0.05,7.628951924593067E-4,-5.029322692678147E11]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4288 / 5552 = 0.7723
BLEU_precision(3) = 3420 / 5352 = 0.6390
BLEU_precision(4) = 2666 / 5152 = 0.5175
BLEU_precision = 0.7109
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.7109

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [-12.464347710289957,-0.6577977590753961,-5.469906598431563E15]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 3945 / 5552 = 0.7106
BLEU_precision(3) = 2871 / 5352 = 0.5364
BLEU_precision(4) = 1975 / 5152 = 0.3833
BLEU_precision = 0.6183
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.6183

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [-12.464347710289957,-0.6577977590753961,-5.469906598431563E15]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 3945 / 5552 = 0.7106
BLEU_precision(3) = 2871 / 5352 = 0.5364
BLEU_precision(4) = 1975 / 5152 = 0.3833
BLEU_precision = 0.6183
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.6183

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [-12.464347710289957,-0.6577977590753961,-5.469906598431563E15]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 3945 / 5552 = 0.7106
BLEU_precision(3) = 2871 / 5352 = 0.5364
BLEU_precision(4) = 1975 / 5152 = 0.3833
BLEU_precision = 0.6183
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.6183

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [0.05,-0.2974935383022126,0.175]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4406 / 5552 = 0.7936
BLEU_precision(3) = 3653 / 5352 = 0.6825
BLEU_precision(4) = 2995 / 5152 = 0.5813
BLEU_precision = 0.7491
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.7491

 
	========================================================
train:200 sentences
=> Optimizing Lambda: [-19.864606864529904,4.153308154484208E15,-1.1706222002748015]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4296 / 5552 = 0.7738
BLEU_precision(3) = 3428 / 5352 = 0.6405
BLEU_precision(4) = 2688 / 5152 = 0.5217
BLEU_precision = 0.7131
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.7131

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
=> Optimizing Lambda: [-1.0529148517942134E-9,-0.6577977590753961,0.46016061237234096]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9570 / 12293 = 0.7785
BLEU_precision(3) = 7772 / 11768 = 0.6604
BLEU_precision(4) = 6261 / 11244 = 0.5568
BLEU_precision = 0.7315
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7315

 
	========================================================
train:200 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
=> Optimizing Lambda: [0.04699954805175292,2.750969892442886E12,4.3698727375931856E14]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4570 / 5552 = 0.8231
BLEU_precision(3) = 3897 / 5352 = 0.7281
BLEU_precision(4) = 3308 / 5152 = 0.6421
BLEU_precision = 0.7876
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.7876

 
	========================================================
train:200 sentences
NGRAM SMOOTH Method: Add one Smoothing
=> Optimizing Lambda: [-158.13593414132416,2.0577786611560332E13,6.786210296750555E14]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4595 / 5552 = 0.8276
BLEU_precision(3) = 3940 / 5352 = 0.7362
BLEU_precision(4) = 3356 / 5152 = 0.6514
BLEU_precision = 0.7937
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.7937

 
	========================================================
train:200 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
=> Optimizing Lambda: [-70.69801203219343,4.6898228242528456E16,-2.7457749172640007]
test:200 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 5752 / 5752 = 1.0000
BLEU_precision(2) = 4323 / 5552 = 0.7786
BLEU_precision(3) = 3499 / 5352 = 0.6538
BLEU_precision(4) = 2796 / 5152 = 0.5427
BLEU_precision = 0.7250
Length of candidate corpus = 5752
Effective length of reference corpus = 5752
BLEU_BP = 1.0000
  => BLEU = 0.7250

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
=> Optimizing Lambda: [-0.6109403606749327,1.8368550528726916E14,3.97771370237394E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10211 / 12293 = 0.8306
BLEU_precision(3) = 8761 / 11768 = 0.7445
BLEU_precision(4) = 7497 / 11244 = 0.6668
BLEU_precision = 0.8013
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8013

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
=> Optimizing Lambda: [-0.00986021299222462,7.27413172484976E17,2.2288334641864368E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10127 / 12293 = 0.8238
BLEU_precision(3) = 8613 / 11768 = 0.7319
BLEU_precision(4) = 7323 / 11244 = 0.6513
BLEU_precision = 0.7916
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7916

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
=> Optimizing Lambda: [-0.00986021299222462,7.27413172484976E17,2.2288334641864368E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10127 / 12293 = 0.8238
BLEU_precision(3) = 8613 / 11768 = 0.7319
BLEU_precision(4) = 7323 / 11244 = 0.6513
BLEU_precision = 0.7916
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7916

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
=> Optimizing Lambda: [-0.6541450753703264,2.8545816904647444E14,3.7796424090827615E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10236 / 12293 = 0.8327
BLEU_precision(3) = 8775 / 11768 = 0.7457
BLEU_precision(4) = 7512 / 11244 = 0.6681
BLEU_precision = 0.8025
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8025

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
=> Optimizing Lambda: [-1562.2322623758394,4.9088026535565776E16,-4.624065047234116]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9227 / 12293 = 0.7506
BLEU_precision(3) = 7213 / 11768 = 0.6129
BLEU_precision(4) = 5523 / 11244 = 0.4912
BLEU_precision = 0.6895
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6895

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.05833333333333313,1.0269728137952615E8,1.8452841196372424E12]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 108 / 136 = 0.7941
BLEU_precision(3) = 87 / 126 = 0.6905
BLEU_precision(4) = 69 / 116 = 0.5948
BLEU_precision = 0.7557
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.7557

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.04157087836698567,3928384.7705485113,6.658414057524934E10]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 111 / 136 = 0.8162
BLEU_precision(3) = 93 / 126 = 0.7381
BLEU_precision(4) = 78 / 116 = 0.6724
BLEU_precision = 0.7978
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.7978

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [-2.1439711198072344,-121857.43924850518,-0.028243239438093603]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 100 / 136 = 0.7353
BLEU_precision(3) = 76 / 126 = 0.6032
BLEU_precision(4) = 55 / 116 = 0.4741
BLEU_precision = 0.6772
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.6772

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.05833333333333313,1.0269728137952615E8,1.8452841196372424E12]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 108 / 136 = 0.7941
BLEU_precision(3) = 87 / 126 = 0.6905
BLEU_precision(4) = 69 / 116 = 0.5948
BLEU_precision = 0.7557
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.7557

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.058333333225435276,3928384.7705485113,6.658414057524934E10]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 111 / 136 = 0.8162
BLEU_precision(3) = 93 / 126 = 0.7381
BLEU_precision(4) = 78 / 116 = 0.6724
BLEU_precision = 0.7978
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.7978

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [-2.1439711198072344,-121857.43924850518,-0.04492943922115955]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 100 / 136 = 0.7353
BLEU_precision(3) = 76 / 126 = 0.6032
BLEU_precision(4) = 55 / 116 = 0.4741
BLEU_precision = 0.6772
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.6772

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.05833333333333313,1.0269728137952615E8,1.8452841196372424E12]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 108 / 136 = 0.7941
BLEU_precision(3) = 87 / 126 = 0.6905
BLEU_precision(4) = 69 / 116 = 0.5948
BLEU_precision = 0.7557
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.7557

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.058333333225435276,3928384.7705485113,6.658414057524934E10]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 111 / 136 = 0.8162
BLEU_precision(3) = 93 / 126 = 0.7381
BLEU_precision(4) = 78 / 116 = 0.6724
BLEU_precision = 0.7978
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.7978

 
	========================================================
train:20 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [-7.6503833727100705,277.48735053002264,0.07656767362683481]
test:10 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 146 / 146 = 1.0000
BLEU_precision(2) = 94 / 136 = 0.6912
BLEU_precision(3) = 69 / 126 = 0.5476
BLEU_precision(4) = 47 / 116 = 0.4052
BLEU_precision = 0.6258
Length of candidate corpus = 146
Effective length of reference corpus = 146
BLEU_BP = 1.0000
  => BLEU = 0.6258

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.027034017423342754,1.3781151528452435E15,2.294055266540741E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10433 / 12293 = 0.8487
BLEU_precision(3) = 8969 / 11768 = 0.7622
BLEU_precision(4) = 7705 / 11244 = 0.6853
BLEU_precision = 0.8159
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8159

 
	========================================================
train:500 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.027034017423342754,1.3781151528452435E15,2.294055266540741E15]
test:840 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19469 / 19469 = 1.0000
BLEU_precision(2) = 15726 / 18629 = 0.8442
BLEU_precision(3) = 13398 / 17790 = 0.7531
BLEU_precision(4) = 11402 / 16954 = 0.6725
BLEU_precision = 0.8086
Length of candidate corpus = 19469
Effective length of reference corpus = 19469
BLEU_BP = 1.0000
  => BLEU = 0.8086

 
	========================================================
train:500 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.10634238705240086,2.0009103630428118E12,1.9454333883344635E15]
test:840 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19469 / 19469 = 1.0000
BLEU_precision(2) = 15717 / 18629 = 0.8437
BLEU_precision(3) = 13454 / 17790 = 0.7563
BLEU_precision(4) = 11473 / 16954 = 0.6767
BLEU_precision = 0.8106
Length of candidate corpus = 19469
Effective length of reference corpus = 19469
BLEU_BP = 1.0000
  => BLEU = 0.8106

 
	========================================================
train:500 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.09216509025179964,-5603.7100178219935,0.1865907287992612]
test:840 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19469 / 19469 = 1.0000
BLEU_precision(2) = 13703 / 18629 = 0.7356
BLEU_precision(3) = 10395 / 17790 = 0.5843
BLEU_precision(4) = 7684 / 16954 = 0.4532
BLEU_precision = 0.6644
Length of candidate corpus = 19469
Effective length of reference corpus = 19469
BLEU_BP = 1.0000
  => BLEU = 0.6644

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.027034017423342754,1.3781151528452435E15,2.294055266540741E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10433 / 12293 = 0.8487
BLEU_precision(3) = 8969 / 11768 = 0.7622
BLEU_precision(4) = 7705 / 11244 = 0.6853
BLEU_precision = 0.8159
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8159

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.10634238705240086,2.0009103630428118E12,1.9454333883344635E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10455 / 12293 = 0.8505
BLEU_precision(3) = 9036 / 11768 = 0.7678
BLEU_precision(4) = 7793 / 11244 = 0.6931
BLEU_precision = 0.8202
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8202

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.09216509025179964,-5603.7100178219935,0.1865907287992612]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9152 / 12293 = 0.7445
BLEU_precision(3) = 7038 / 11768 = 0.5981
BLEU_precision(4) = 5298 / 11244 = 0.4712
BLEU_precision = 0.6768
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6768

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.089310397868531,2.5544387847821543E12,4.329928211728505E15]
test:807 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18890 / 18890 = 1.0000
BLEU_precision(2) = 15163 / 18083 = 0.8385
BLEU_precision(3) = 12895 / 17277 = 0.7464
BLEU_precision(4) = 10946 / 16473 = 0.6645
BLEU_precision = 0.8030
Length of candidate corpus = 18890
Effective length of reference corpus = 18890
BLEU_BP = 1.0000
  => BLEU = 0.8030

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.05737837673665225,1.2308323540496023E14,8.663440353323336E14]
test:807 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18890 / 18890 = 1.0000
BLEU_precision(2) = 15134 / 18083 = 0.8369
BLEU_precision(3) = 12847 / 17277 = 0.7436
BLEU_precision(4) = 10884 / 16473 = 0.6607
BLEU_precision = 0.8008
Length of candidate corpus = 18890
Effective length of reference corpus = 18890
BLEU_BP = 1.0000
  => BLEU = 0.8008

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.07012689304315362,1.92357979585956E12,2.5491746876125005E15]
test:807 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18890 / 18890 = 1.0000
BLEU_precision(2) = 15269 / 18083 = 0.8444
BLEU_precision(3) = 13087 / 17277 = 0.7575
BLEU_precision(4) = 11179 / 16473 = 0.6786
BLEU_precision = 0.8117
Length of candidate corpus = 18890
Effective length of reference corpus = 18890
BLEU_BP = 1.0000
  => BLEU = 0.8117

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.1306696403802074,432469.59025679,-0.2915414993549898]
test:807 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18890 / 18890 = 1.0000
BLEU_precision(2) = 13130 / 18083 = 0.7261
BLEU_precision(3) = 9805 / 17277 = 0.5675
BLEU_precision(4) = 7101 / 16473 = 0.4311
BLEU_precision = 0.6492
Length of candidate corpus = 18890
Effective length of reference corpus = 18890
BLEU_BP = 1.0000
  => BLEU = 0.6492

 
	========================================================
train:313 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.11852396885244931,3.355179610048263E14,4.5011205966216406E14]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13690 / 13690 = 1.0000
BLEU_precision(2) = 11014 / 13164 = 0.8367
BLEU_precision(3) = 9396 / 12638 = 0.7435
BLEU_precision(4) = 7999 / 12113 = 0.6604
BLEU_precision = 0.8006
Length of candidate corpus = 13690
Effective length of reference corpus = 13690
BLEU_BP = 1.0000
  => BLEU = 0.8006

 
	========================================================
train:313 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.03396242505419221,9.94186179208302E12,7.977799109025406E14]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13690 / 13690 = 1.0000
BLEU_precision(2) = 11143 / 13164 = 0.8465
BLEU_precision(3) = 9614 / 12638 = 0.7607
BLEU_precision(4) = 8271 / 12113 = 0.6828
BLEU_precision = 0.8143
Length of candidate corpus = 13690
Effective length of reference corpus = 13690
BLEU_BP = 1.0000
  => BLEU = 0.8143

 
	========================================================
train:313 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.68
=> Optimizing Lambda: [0.10669235707306957,-13785.61832069162,-0.14813469595180176]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13690 / 13690 = 1.0000
BLEU_precision(2) = 10030 / 13164 = 0.7619
BLEU_precision(3) = 7892 / 12638 = 0.6245
BLEU_precision(4) = 6114 / 12113 = 0.5047
BLEU_precision = 0.7000
Length of candidate corpus = 13690
Effective length of reference corpus = 13690
BLEU_BP = 1.0000
  => BLEU = 0.7000

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.75
=> Optimizing Lambda: [0.12706887154182633,4.513755690912956E14,3.7863069915638705E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10478 / 12293 = 0.8524
BLEU_precision(3) = 8991 / 11768 = 0.7640
BLEU_precision(4) = 7704 / 11244 = 0.6852
BLEU_precision = 0.8173
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8173

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.75
=> Optimizing Lambda: [0.10009934854908539,2.0009103630428513E12,1.945506862660054E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10562 / 12293 = 0.8592
BLEU_precision(3) = 9131 / 11768 = 0.7759
BLEU_precision(4) = 7878 / 11244 = 0.7006
BLEU_precision = 0.8267
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8267

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.75
=> Optimizing Lambda: [0.6491144004527248,-8310.03742442578,-0.18780324058604295]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9362 / 12293 = 0.7616
BLEU_precision(3) = 7289 / 11768 = 0.6194
BLEU_precision(4) = 5574 / 11244 = 0.4957
BLEU_precision = 0.6954
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6954

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.8
=> Optimizing Lambda: [0.12706887154182633,4.513755690912956E14,3.7863069915638705E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10478 / 12293 = 0.8524
BLEU_precision(3) = 8991 / 11768 = 0.7640
BLEU_precision(4) = 7704 / 11244 = 0.6852
BLEU_precision = 0.8173
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8173

 
MAX========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.8
=> Optimizing Lambda: [0.10009934854908539,2.0009103630428513E12,1.945506862660054E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10562 / 12293 = 0.8592
BLEU_precision(3) = 9131 / 11768 = 0.7759
BLEU_precision(4) = 7878 / 11244 = 0.7006
BLEU_precision = 0.8267
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8267

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.8
=> Optimizing Lambda: [0.648708846356208,-8254.27072852004,-0.1835835803418677]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9362 / 12293 = 0.7616
BLEU_precision(3) = 7289 / 11768 = 0.6194
BLEU_precision(4) = 5574 / 11244 = 0.4957
BLEU_precision = 0.6954
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6954

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.9
=> Optimizing Lambda: [0.16532383605976914,2.0347150181513515E15,3.2364827997598635E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9428 / 12293 = 0.7669
BLEU_precision(3) = 7290 / 11768 = 0.6195
BLEU_precision(4) = 5516 / 11244 = 0.4906
BLEU_precision = 0.6948
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6948

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.9
=> Optimizing Lambda: [0.11159072132232276,5.029526686475321E13,2.22354981746298E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9477 / 12293 = 0.7709
BLEU_precision(3) = 7366 / 11768 = 0.6259
BLEU_precision(4) = 5602 / 11244 = 0.4982
BLEU_precision = 0.7002
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7002

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.027034017423342754,1.3781151528452435E15,2.16922622796959E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10431 / 12293 = 0.8485
BLEU_precision(3) = 8966 / 11768 = 0.7619
BLEU_precision(4) = 7701 / 11244 = 0.6849
BLEU_precision = 0.8157
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8157

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.10634238705240086,2.0009103630428118E12,1.9454333883344635E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10454 / 12293 = 0.8504
BLEU_precision(3) = 9035 / 11768 = 0.7678
BLEU_precision(4) = 7791 / 11244 = 0.6929
BLEU_precision = 0.8201
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8201

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.13304805362235392,-4277.99232306145,0.020745416904829988]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9162 / 12293 = 0.7453
BLEU_precision(3) = 7053 / 11768 = 0.5993
BLEU_precision(4) = 5314 / 11244 = 0.4726
BLEU_precision = 0.6778
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6778

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [-0.00986021299222462,7.27413172484976E17,2.2288334641864368E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10126 / 12293 = 0.8237
BLEU_precision(3) = 8611 / 11768 = 0.7317
BLEU_precision(4) = 7320 / 11244 = 0.6510
BLEU_precision = 0.7915
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7915

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [-0.17712999050582473,2.854581690464744E14,1.3111687734407232E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10234 / 12293 = 0.8325
BLEU_precision(3) = 8774 / 11768 = 0.7456
BLEU_precision(4) = 7514 / 11244 = 0.6683
BLEU_precision = 0.8025
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8025

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [-0.00986021299222462,7.27413172484976E17,2.2288334641864368E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10126 / 12293 = 0.8237
BLEU_precision(3) = 8611 / 11768 = 0.7317
BLEU_precision(4) = 7320 / 11244 = 0.6510
BLEU_precision = 0.7915
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7915

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [-0.17712999050582473,2.854581690464744E14,1.3111687734407232E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10234 / 12293 = 0.8325
BLEU_precision(3) = 8774 / 11768 = 0.7456
BLEU_precision(4) = 7514 / 11244 = 0.6683
BLEU_precision = 0.8025
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8025

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,2.7253109831386456E14]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10420 / 12293 = 0.8476
BLEU_precision(3) = 9005 / 11768 = 0.7652
BLEU_precision(4) = 7774 / 11244 = 0.6914
BLEU_precision = 0.8183
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8183

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.04975277907319677,0.2,6.915585479814105E13]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10503 / 12293 = 0.8544
BLEU_precision(3) = 9154 / 11768 = 0.7779
BLEU_precision(4) = 7957 / 11244 = 0.7077
BLEU_precision = 0.8281
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8281

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.584560089096255,-0.1]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9351 / 12293 = 0.7607
BLEU_precision(3) = 7360 / 11768 = 0.6254
BLEU_precision(4) = 5707 / 11244 = 0.5076
BLEU_precision = 0.7010
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7010

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10283 / 12293 = 0.8365
BLEU_precision(3) = 8754 / 11768 = 0.7439
BLEU_precision(4) = 7437 / 11244 = 0.6614
BLEU_precision = 0.8010
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8010

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:536 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13023 / 13023 = 1.0000
BLEU_precision(2) = 10458 / 12487 = 0.8375
BLEU_precision(3) = 8909 / 11952 = 0.7454
BLEU_precision(4) = 7572 / 11418 = 0.6632
BLEU_precision = 0.8021
Length of candidate corpus = 13023
Effective length of reference corpus = 13023
BLEU_BP = 1.0000
  => BLEU = 0.8021

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:546 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13263 / 13263 = 1.0000
BLEU_precision(2) = 10653 / 12717 = 0.8377
BLEU_precision(3) = 9076 / 12172 = 0.7456
BLEU_precision(4) = 7714 / 11628 = 0.6634
BLEU_precision = 0.8023
Length of candidate corpus = 13263
Effective length of reference corpus = 13263
BLEU_BP = 1.0000
  => BLEU = 0.8023

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:556 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13469 / 13469 = 1.0000
BLEU_precision(2) = 10833 / 12913 = 0.8389
BLEU_precision(3) = 9237 / 12358 = 0.7475
BLEU_precision(4) = 7859 / 11804 = 0.6658
BLEU_precision = 0.8038
Length of candidate corpus = 13469
Effective length of reference corpus = 13469
BLEU_BP = 1.0000
  => BLEU = 0.8038

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:566 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13702 / 13702 = 1.0000
BLEU_precision(2) = 11006 / 13136 = 0.8379
BLEU_precision(3) = 9372 / 12571 = 0.7455
BLEU_precision(4) = 7962 / 12007 = 0.6631
BLEU_precision = 0.8022
Length of candidate corpus = 13702
Effective length of reference corpus = 13702
BLEU_BP = 1.0000
  => BLEU = 0.8022

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:576 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13891 / 13891 = 1.0000
BLEU_precision(2) = 11133 / 13315 = 0.8361
BLEU_precision(3) = 9468 / 12740 = 0.7432
BLEU_precision(4) = 8035 / 12166 = 0.6604
BLEU_precision = 0.8004
Length of candidate corpus = 13891
Effective length of reference corpus = 13891
BLEU_BP = 1.0000
  => BLEU = 0.8004

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:586 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 14130 / 14130 = 1.0000
BLEU_precision(2) = 11319 / 13544 = 0.8357
BLEU_precision(3) = 9616 / 12959 = 0.7420
BLEU_precision(4) = 8158 / 12375 = 0.6592
BLEU_precision = 0.7996
Length of candidate corpus = 14130
Effective length of reference corpus = 14130
BLEU_BP = 1.0000
  => BLEU = 0.7996

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:596 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 14342 / 14342 = 1.0000
BLEU_precision(2) = 11472 / 13746 = 0.8346
BLEU_precision(3) = 9733 / 13151 = 0.7401
BLEU_precision(4) = 8247 / 12557 = 0.6568
BLEU_precision = 0.7981
Length of candidate corpus = 14342
Effective length of reference corpus = 14342
BLEU_BP = 1.0000
  => BLEU = 0.7981

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:606 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 14593 / 14593 = 1.0000
BLEU_precision(2) = 11667 / 13987 = 0.8341
BLEU_precision(3) = 9896 / 13382 = 0.7395
BLEU_precision(4) = 8386 / 12778 = 0.6563
BLEU_precision = 0.7977
Length of candidate corpus = 14593
Effective length of reference corpus = 14593
BLEU_BP = 1.0000
  => BLEU = 0.7977

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:616 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 14847 / 14847 = 1.0000
BLEU_precision(2) = 11864 / 14231 = 0.8337
BLEU_precision(3) = 10060 / 13616 = 0.7388
BLEU_precision(4) = 8522 / 13002 = 0.6554
BLEU_precision = 0.7971
Length of candidate corpus = 14847
Effective length of reference corpus = 14847
BLEU_BP = 1.0000
  => BLEU = 0.7971

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:626 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15072 / 15072 = 1.0000
BLEU_precision(2) = 12026 / 14446 = 0.8325
BLEU_precision(3) = 10190 / 13821 = 0.7373
BLEU_precision(4) = 8626 / 13197 = 0.6536
BLEU_precision = 0.7959
Length of candidate corpus = 15072
Effective length of reference corpus = 15072
BLEU_BP = 1.0000
  => BLEU = 0.7959

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:636 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15277 / 15277 = 1.0000
BLEU_precision(2) = 12184 / 14641 = 0.8322
BLEU_precision(3) = 10325 / 14006 = 0.7372
BLEU_precision(4) = 8740 / 13372 = 0.6536
BLEU_precision = 0.7958
Length of candidate corpus = 15277
Effective length of reference corpus = 15277
BLEU_BP = 1.0000
  => BLEU = 0.7958

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:646 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15471 / 15471 = 1.0000
BLEU_precision(2) = 12337 / 14825 = 0.8322
BLEU_precision(3) = 10452 / 14180 = 0.7371
BLEU_precision(4) = 8844 / 13536 = 0.6534
BLEU_precision = 0.7957
Length of candidate corpus = 15471
Effective length of reference corpus = 15471
BLEU_BP = 1.0000
  => BLEU = 0.7957

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:656 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15642 / 15642 = 1.0000
BLEU_precision(2) = 12466 / 14986 = 0.8318
BLEU_precision(3) = 10559 / 14331 = 0.7368
BLEU_precision(4) = 8935 / 13678 = 0.6532
BLEU_precision = 0.7955
Length of candidate corpus = 15642
Effective length of reference corpus = 15642
BLEU_BP = 1.0000
  => BLEU = 0.7955

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:666 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15854 / 15854 = 1.0000
BLEU_precision(2) = 12615 / 15188 = 0.8306
BLEU_precision(3) = 10679 / 14523 = 0.7353
BLEU_precision(4) = 9033 / 13860 = 0.6517
BLEU_precision = 0.7943
Length of candidate corpus = 15854
Effective length of reference corpus = 15854
BLEU_BP = 1.0000
  => BLEU = 0.7943

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:676 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16083 / 16083 = 1.0000
BLEU_precision(2) = 12789 / 15407 = 0.8301
BLEU_precision(3) = 10822 / 14732 = 0.7346
BLEU_precision(4) = 9152 / 14059 = 0.6510
BLEU_precision = 0.7937
Length of candidate corpus = 16083
Effective length of reference corpus = 16083
BLEU_BP = 1.0000
  => BLEU = 0.7937

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:686 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16243 / 16243 = 1.0000
BLEU_precision(2) = 12908 / 15557 = 0.8297
BLEU_precision(3) = 10913 / 14872 = 0.7338
BLEU_precision(4) = 9220 / 14189 = 0.6498
BLEU_precision = 0.7931
Length of candidate corpus = 16243
Effective length of reference corpus = 16243
BLEU_BP = 1.0000
  => BLEU = 0.7931

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:696 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16506 / 16506 = 1.0000
BLEU_precision(2) = 13126 / 15810 = 0.8302
BLEU_precision(3) = 11095 / 15115 = 0.7340
BLEU_precision(4) = 9374 / 14422 = 0.6500
BLEU_precision = 0.7933
Length of candidate corpus = 16506
Effective length of reference corpus = 16506
BLEU_BP = 1.0000
  => BLEU = 0.7933

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:706 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16714 / 16714 = 1.0000
BLEU_precision(2) = 13291 / 16008 = 0.8303
BLEU_precision(3) = 11235 / 15303 = 0.7342
BLEU_precision(4) = 9490 / 14600 = 0.6500
BLEU_precision = 0.7934
Length of candidate corpus = 16714
Effective length of reference corpus = 16714
BLEU_BP = 1.0000
  => BLEU = 0.7934

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:716 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16985 / 16985 = 1.0000
BLEU_precision(2) = 13503 / 16269 = 0.8300
BLEU_precision(3) = 11408 / 15554 = 0.7334
BLEU_precision(4) = 9628 / 14841 = 0.6487
BLEU_precision = 0.7927
Length of candidate corpus = 16985
Effective length of reference corpus = 16985
BLEU_BP = 1.0000
  => BLEU = 0.7927

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:726 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 17222 / 17222 = 1.0000
BLEU_precision(2) = 13688 / 16496 = 0.8298
BLEU_precision(3) = 11565 / 15771 = 0.7333
BLEU_precision(4) = 9758 / 15048 = 0.6485
BLEU_precision = 0.7926
Length of candidate corpus = 17222
Effective length of reference corpus = 17222
BLEU_BP = 1.0000
  => BLEU = 0.7926

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:736 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 17462 / 17462 = 1.0000
BLEU_precision(2) = 13883 / 16726 = 0.8300
BLEU_precision(3) = 11730 / 15991 = 0.7335
BLEU_precision(4) = 9896 / 15258 = 0.6486
BLEU_precision = 0.7927
Length of candidate corpus = 17462
Effective length of reference corpus = 17462
BLEU_BP = 1.0000
  => BLEU = 0.7927

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:746 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 17718 / 17718 = 1.0000
BLEU_precision(2) = 14079 / 16972 = 0.8295
BLEU_precision(3) = 11894 / 16227 = 0.7330
BLEU_precision(4) = 10031 / 15484 = 0.6478
BLEU_precision = 0.7922
Length of candidate corpus = 17718
Effective length of reference corpus = 17718
BLEU_BP = 1.0000
  => BLEU = 0.7922

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:756 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 17931 / 17931 = 1.0000
BLEU_precision(2) = 14243 / 17175 = 0.8293
BLEU_precision(3) = 12029 / 16420 = 0.7326
BLEU_precision(4) = 10141 / 15667 = 0.6473
BLEU_precision = 0.7919
Length of candidate corpus = 17931
Effective length of reference corpus = 17931
BLEU_BP = 1.0000
  => BLEU = 0.7919

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:766 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18085 / 18085 = 1.0000
BLEU_precision(2) = 14364 / 17319 = 0.8294
BLEU_precision(3) = 12130 / 16554 = 0.7328
BLEU_precision(4) = 10225 / 15791 = 0.6475
BLEU_precision = 0.7920
Length of candidate corpus = 18085
Effective length of reference corpus = 18085
BLEU_BP = 1.0000
  => BLEU = 0.7920

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:776 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18296 / 18296 = 1.0000
BLEU_precision(2) = 14536 / 17520 = 0.8297
BLEU_precision(3) = 12273 / 16745 = 0.7329
BLEU_precision(4) = 10342 / 15972 = 0.6475
BLEU_precision = 0.7921
Length of candidate corpus = 18296
Effective length of reference corpus = 18296
BLEU_BP = 1.0000
  => BLEU = 0.7921

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:786 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18472 / 18472 = 1.0000
BLEU_precision(2) = 14683 / 17686 = 0.8302
BLEU_precision(3) = 12398 / 16901 = 0.7336
BLEU_precision(4) = 10445 / 16118 = 0.6480
BLEU_precision = 0.7926
Length of candidate corpus = 18472
Effective length of reference corpus = 18472
BLEU_BP = 1.0000
  => BLEU = 0.7926

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:796 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18663 / 18663 = 1.0000
BLEU_precision(2) = 14832 / 17867 = 0.8301
BLEU_precision(3) = 12515 / 17072 = 0.7331
BLEU_precision(4) = 10535 / 16279 = 0.6472
BLEU_precision = 0.7922
Length of candidate corpus = 18663
Effective length of reference corpus = 18663
BLEU_BP = 1.0000
  => BLEU = 0.7922

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:806 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18870 / 18870 = 1.0000
BLEU_precision(2) = 15003 / 18064 = 0.8305
BLEU_precision(3) = 12657 / 17259 = 0.7334
BLEU_precision(4) = 10653 / 16456 = 0.6474
BLEU_precision = 0.7924
Length of candidate corpus = 18870
Effective length of reference corpus = 18870
BLEU_BP = 1.0000
  => BLEU = 0.7924

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:816 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19082 / 19082 = 1.0000
BLEU_precision(2) = 15173 / 18266 = 0.8307
BLEU_precision(3) = 12802 / 17451 = 0.7336
BLEU_precision(4) = 10773 / 16638 = 0.6475
BLEU_precision = 0.7926
Length of candidate corpus = 19082
Effective length of reference corpus = 19082
BLEU_BP = 1.0000
  => BLEU = 0.7926

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:826 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19250 / 19250 = 1.0000
BLEU_precision(2) = 15305 / 18424 = 0.8307
BLEU_precision(3) = 12909 / 17599 = 0.7335
BLEU_precision(4) = 10859 / 16776 = 0.6473
BLEU_precision = 0.7925
Length of candidate corpus = 19250
Effective length of reference corpus = 19250
BLEU_BP = 1.0000
  => BLEU = 0.7925

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:836 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19415 / 19415 = 1.0000
BLEU_precision(2) = 15417 / 18579 = 0.8298
BLEU_precision(3) = 12994 / 17744 = 0.7323
BLEU_precision(4) = 10921 / 16912 = 0.6458
BLEU_precision = 0.7915
Length of candidate corpus = 19415
Effective length of reference corpus = 19415
BLEU_BP = 1.0000
  => BLEU = 0.7915

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:846 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19572 / 19572 = 1.0000
BLEU_precision(2) = 15537 / 18726 = 0.8297
BLEU_precision(3) = 13094 / 17881 = 0.7323
BLEU_precision(4) = 11006 / 17039 = 0.6459
BLEU_precision = 0.7915
Length of candidate corpus = 19572
Effective length of reference corpus = 19572
BLEU_BP = 1.0000
  => BLEU = 0.7915

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:856 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19701 / 19701 = 1.0000
BLEU_precision(2) = 15638 / 18845 = 0.8298
BLEU_precision(3) = 13175 / 17990 = 0.7324
BLEU_precision(4) = 11069 / 17138 = 0.6459
BLEU_precision = 0.7915
Length of candidate corpus = 19701
Effective length of reference corpus = 19701
BLEU_BP = 1.0000
  => BLEU = 0.7915

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:866 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19852 / 19852 = 1.0000
BLEU_precision(2) = 15748 / 18986 = 0.8295
BLEU_precision(3) = 13266 / 18121 = 0.7321
BLEU_precision(4) = 11147 / 17259 = 0.6459
BLEU_precision = 0.7914
Length of candidate corpus = 19852
Effective length of reference corpus = 19852
BLEU_BP = 1.0000
  => BLEU = 0.7914

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:876 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20066 / 20066 = 1.0000
BLEU_precision(2) = 15910 / 19190 = 0.8291
BLEU_precision(3) = 13401 / 18315 = 0.7317
BLEU_precision(4) = 11265 / 17443 = 0.6458
BLEU_precision = 0.7912
Length of candidate corpus = 20066
Effective length of reference corpus = 20066
BLEU_BP = 1.0000
  => BLEU = 0.7912

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:886 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20255 / 20255 = 1.0000
BLEU_precision(2) = 16048 / 19369 = 0.8285
BLEU_precision(3) = 13510 / 18484 = 0.7309
BLEU_precision(4) = 11347 / 17602 = 0.6446
BLEU_precision = 0.7904
Length of candidate corpus = 20255
Effective length of reference corpus = 20255
BLEU_BP = 1.0000
  => BLEU = 0.7904

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:896 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20467 / 20467 = 1.0000
BLEU_precision(2) = 16216 / 19571 = 0.8286
BLEU_precision(3) = 13648 / 18676 = 0.7308
BLEU_precision(4) = 11458 / 17784 = 0.6443
BLEU_precision = 0.7903
Length of candidate corpus = 20467
Effective length of reference corpus = 20467
BLEU_BP = 1.0000
  => BLEU = 0.7903

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:906 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20528 / 20528 = 1.0000
BLEU_precision(2) = 16255 / 19622 = 0.8284
BLEU_precision(3) = 13677 / 18718 = 0.7307
BLEU_precision(4) = 11479 / 17817 = 0.6443
BLEU_precision = 0.7902
Length of candidate corpus = 20528
Effective length of reference corpus = 20528
BLEU_BP = 1.0000
  => BLEU = 0.7902

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:916 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20723 / 20723 = 1.0000
BLEU_precision(2) = 16400 / 19807 = 0.8280
BLEU_precision(3) = 13793 / 18893 = 0.7301
BLEU_precision(4) = 11568 / 17982 = 0.6433
BLEU_precision = 0.7897
Length of candidate corpus = 20723
Effective length of reference corpus = 20723
BLEU_BP = 1.0000
  => BLEU = 0.7897

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:926 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20979 / 20979 = 1.0000
BLEU_precision(2) = 16617 / 20053 = 0.8287
BLEU_precision(3) = 13984 / 19129 = 0.7310
BLEU_precision(4) = 11735 / 18208 = 0.6445
BLEU_precision = 0.7905
Length of candidate corpus = 20979
Effective length of reference corpus = 20979
BLEU_BP = 1.0000
  => BLEU = 0.7905

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:936 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 21257 / 21257 = 1.0000
BLEU_precision(2) = 16835 / 20321 = 0.8285
BLEU_precision(3) = 14163 / 19387 = 0.7305
BLEU_precision(4) = 11879 / 18456 = 0.6436
BLEU_precision = 0.7900
Length of candidate corpus = 21257
Effective length of reference corpus = 21257
BLEU_BP = 1.0000
  => BLEU = 0.7900

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:946 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 21490 / 21490 = 1.0000
BLEU_precision(2) = 17022 / 20544 = 0.8286
BLEU_precision(3) = 14317 / 19600 = 0.7305
BLEU_precision(4) = 12005 / 18659 = 0.6434
BLEU_precision = 0.7899
Length of candidate corpus = 21490
Effective length of reference corpus = 21490
BLEU_BP = 1.0000
  => BLEU = 0.7899

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:956 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 21812 / 21812 = 1.0000
BLEU_precision(2) = 17274 / 20856 = 0.8283
BLEU_precision(3) = 14526 / 19902 = 0.7299
BLEU_precision(4) = 12176 / 18951 = 0.6425
BLEU_precision = 0.7894
Length of candidate corpus = 21812
Effective length of reference corpus = 21812
BLEU_BP = 1.0000
  => BLEU = 0.7894

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:966 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 22019 / 22019 = 1.0000
BLEU_precision(2) = 17444 / 21053 = 0.8286
BLEU_precision(3) = 14671 / 20089 = 0.7303
BLEU_precision(4) = 12299 / 19128 = 0.6430
BLEU_precision = 0.7898
Length of candidate corpus = 22019
Effective length of reference corpus = 22019
BLEU_BP = 1.0000
  => BLEU = 0.7898

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:976 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 22203 / 22203 = 1.0000
BLEU_precision(2) = 17607 / 21227 = 0.8295
BLEU_precision(3) = 14816 / 20253 = 0.7315
BLEU_precision(4) = 12429 / 19282 = 0.6446
BLEU_precision = 0.7908
Length of candidate corpus = 22203
Effective length of reference corpus = 22203
BLEU_BP = 1.0000
  => BLEU = 0.7908

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:986 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 22387 / 22387 = 1.0000
BLEU_precision(2) = 17740 / 21401 = 0.8289
BLEU_precision(3) = 14922 / 20417 = 0.7309
BLEU_precision(4) = 12513 / 19436 = 0.6438
BLEU_precision = 0.7903
Length of candidate corpus = 22387
Effective length of reference corpus = 22387
BLEU_BP = 1.0000
  => BLEU = 0.7903

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:996 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 22589 / 22589 = 1.0000
BLEU_precision(2) = 17894 / 21593 = 0.8287
BLEU_precision(3) = 15048 / 20599 = 0.7305
BLEU_precision(4) = 12615 / 19608 = 0.6434
BLEU_precision = 0.7900
Length of candidate corpus = 22589
Effective length of reference corpus = 22589
BLEU_BP = 1.0000
  => BLEU = 0.7900

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10408 / 12293 = 0.8467
BLEU_precision(3) = 8977 / 11768 = 0.7628
BLEU_precision(4) = 7711 / 11244 = 0.6858
BLEU_precision = 0.8158
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8158

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:536 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13023 / 13023 = 1.0000
BLEU_precision(2) = 10583 / 12487 = 0.8475
BLEU_precision(3) = 9132 / 11952 = 0.7641
BLEU_precision(4) = 7846 / 11418 = 0.6872
BLEU_precision = 0.8167
Length of candidate corpus = 13023
Effective length of reference corpus = 13023
BLEU_BP = 1.0000
  => BLEU = 0.8167

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:546 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13263 / 13263 = 1.0000
BLEU_precision(2) = 10773 / 12717 = 0.8471
BLEU_precision(3) = 9291 / 12172 = 0.7633
BLEU_precision(4) = 7977 / 11628 = 0.6860
BLEU_precision = 0.8161
Length of candidate corpus = 13263
Effective length of reference corpus = 13263
BLEU_BP = 1.0000
  => BLEU = 0.8161

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:556 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13469 / 13469 = 1.0000
BLEU_precision(2) = 10953 / 12913 = 0.8482
BLEU_precision(3) = 9452 / 12358 = 0.7648
BLEU_precision(4) = 8122 / 11804 = 0.6881
BLEU_precision = 0.8174
Length of candidate corpus = 13469
Effective length of reference corpus = 13469
BLEU_BP = 1.0000
  => BLEU = 0.8174

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:566 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13702 / 13702 = 1.0000
BLEU_precision(2) = 11126 / 13136 = 0.8470
BLEU_precision(3) = 9591 / 12571 = 0.7629
BLEU_precision(4) = 8231 / 12007 = 0.6855
BLEU_precision = 0.8158
Length of candidate corpus = 13702
Effective length of reference corpus = 13702
BLEU_BP = 1.0000
  => BLEU = 0.8158

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:576 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13891 / 13891 = 1.0000
BLEU_precision(2) = 11260 / 13315 = 0.8457
BLEU_precision(3) = 9696 / 12740 = 0.7611
BLEU_precision(4) = 8311 / 12166 = 0.6831
BLEU_precision = 0.8143
Length of candidate corpus = 13891
Effective length of reference corpus = 13891
BLEU_BP = 1.0000
  => BLEU = 0.8143

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:586 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 14130 / 14130 = 1.0000
BLEU_precision(2) = 11444 / 13544 = 0.8449
BLEU_precision(3) = 9843 / 12959 = 0.7595
BLEU_precision(4) = 8432 / 12375 = 0.6814
BLEU_precision = 0.8132
Length of candidate corpus = 14130
Effective length of reference corpus = 14130
BLEU_BP = 1.0000
  => BLEU = 0.8132

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:596 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 14342 / 14342 = 1.0000
BLEU_precision(2) = 11598 / 13746 = 0.8437
BLEU_precision(3) = 9963 / 13151 = 0.7576
BLEU_precision(4) = 8525 / 12557 = 0.6789
BLEU_precision = 0.8116
Length of candidate corpus = 14342
Effective length of reference corpus = 14342
BLEU_BP = 1.0000
  => BLEU = 0.8116

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:606 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 14593 / 14593 = 1.0000
BLEU_precision(2) = 11803 / 13987 = 0.8439
BLEU_precision(3) = 10137 / 13382 = 0.7575
BLEU_precision(4) = 8672 / 12778 = 0.6787
BLEU_precision = 0.8116
Length of candidate corpus = 14593
Effective length of reference corpus = 14593
BLEU_BP = 1.0000
  => BLEU = 0.8116

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:616 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 14847 / 14847 = 1.0000
BLEU_precision(2) = 12004 / 14231 = 0.8435
BLEU_precision(3) = 10305 / 13616 = 0.7568
BLEU_precision(4) = 8813 / 13002 = 0.6778
BLEU_precision = 0.8111
Length of candidate corpus = 14847
Effective length of reference corpus = 14847
BLEU_BP = 1.0000
  => BLEU = 0.8111

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:626 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15072 / 15072 = 1.0000
BLEU_precision(2) = 12166 / 14446 = 0.8422
BLEU_precision(3) = 10436 / 13821 = 0.7551
BLEU_precision(4) = 8916 / 13197 = 0.6756
BLEU_precision = 0.8096
Length of candidate corpus = 15072
Effective length of reference corpus = 15072
BLEU_BP = 1.0000
  => BLEU = 0.8096

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:636 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15277 / 15277 = 1.0000
BLEU_precision(2) = 12328 / 14641 = 0.8420
BLEU_precision(3) = 10575 / 14006 = 0.7550
BLEU_precision(4) = 9035 / 13372 = 0.6757
BLEU_precision = 0.8096
Length of candidate corpus = 15277
Effective length of reference corpus = 15277
BLEU_BP = 1.0000
  => BLEU = 0.8096

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:646 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15471 / 15471 = 1.0000
BLEU_precision(2) = 12487 / 14825 = 0.8423
BLEU_precision(3) = 10710 / 14180 = 0.7553
BLEU_precision(4) = 9149 / 13536 = 0.6759
BLEU_precision = 0.8098
Length of candidate corpus = 15471
Effective length of reference corpus = 15471
BLEU_BP = 1.0000
  => BLEU = 0.8098

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:656 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15642 / 15642 = 1.0000
BLEU_precision(2) = 12619 / 14986 = 0.8421
BLEU_precision(3) = 10821 / 14331 = 0.7551
BLEU_precision(4) = 9243 / 13678 = 0.6758
BLEU_precision = 0.8096
Length of candidate corpus = 15642
Effective length of reference corpus = 15642
BLEU_BP = 1.0000
  => BLEU = 0.8096

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:666 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15854 / 15854 = 1.0000
BLEU_precision(2) = 12768 / 15188 = 0.8407
BLEU_precision(3) = 10941 / 14523 = 0.7534
BLEU_precision(4) = 9341 / 13860 = 0.6740
BLEU_precision = 0.8083
Length of candidate corpus = 15854
Effective length of reference corpus = 15854
BLEU_BP = 1.0000
  => BLEU = 0.8083

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:676 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16083 / 16083 = 1.0000
BLEU_precision(2) = 12942 / 15407 = 0.8400
BLEU_precision(3) = 11087 / 14732 = 0.7526
BLEU_precision(4) = 9463 / 14059 = 0.6731
BLEU_precision = 0.8077
Length of candidate corpus = 16083
Effective length of reference corpus = 16083
BLEU_BP = 1.0000
  => BLEU = 0.8077

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:686 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16243 / 16243 = 1.0000
BLEU_precision(2) = 13057 / 15557 = 0.8393
BLEU_precision(3) = 11174 / 14872 = 0.7513
BLEU_precision(4) = 9528 / 14189 = 0.6715
BLEU_precision = 0.8067
Length of candidate corpus = 16243
Effective length of reference corpus = 16243
BLEU_BP = 1.0000
  => BLEU = 0.8067

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:696 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16506 / 16506 = 1.0000
BLEU_precision(2) = 13278 / 15810 = 0.8398
BLEU_precision(3) = 11362 / 15115 = 0.7517
BLEU_precision(4) = 9690 / 14422 = 0.6719
BLEU_precision = 0.8070
Length of candidate corpus = 16506
Effective length of reference corpus = 16506
BLEU_BP = 1.0000
  => BLEU = 0.8070

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:706 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16714 / 16714 = 1.0000
BLEU_precision(2) = 13447 / 16008 = 0.8400
BLEU_precision(3) = 11508 / 15303 = 0.7520
BLEU_precision(4) = 9813 / 14600 = 0.6721
BLEU_precision = 0.8072
Length of candidate corpus = 16714
Effective length of reference corpus = 16714
BLEU_BP = 1.0000
  => BLEU = 0.8072

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:716 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16985 / 16985 = 1.0000
BLEU_precision(2) = 13667 / 16269 = 0.8401
BLEU_precision(3) = 11693 / 15554 = 0.7518
BLEU_precision(4) = 9967 / 14841 = 0.6716
BLEU_precision = 0.8070
Length of candidate corpus = 16985
Effective length of reference corpus = 16985
BLEU_BP = 1.0000
  => BLEU = 0.8070

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:726 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 17222 / 17222 = 1.0000
BLEU_precision(2) = 13861 / 16496 = 0.8403
BLEU_precision(3) = 11863 / 15771 = 0.7522
BLEU_precision(4) = 10113 / 15048 = 0.6720
BLEU_precision = 0.8073
Length of candidate corpus = 17222
Effective length of reference corpus = 17222
BLEU_BP = 1.0000
  => BLEU = 0.8073

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:736 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 17462 / 17462 = 1.0000
BLEU_precision(2) = 14057 / 16726 = 0.8404
BLEU_precision(3) = 12030 / 15991 = 0.7523
BLEU_precision(4) = 10254 / 15258 = 0.6720
BLEU_precision = 0.8074
Length of candidate corpus = 17462
Effective length of reference corpus = 17462
BLEU_BP = 1.0000
  => BLEU = 0.8074

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:746 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 17718 / 17718 = 1.0000
BLEU_precision(2) = 14256 / 16972 = 0.8400
BLEU_precision(3) = 12196 / 16227 = 0.7516
BLEU_precision(4) = 10391 / 15484 = 0.6711
BLEU_precision = 0.8068
Length of candidate corpus = 17718
Effective length of reference corpus = 17718
BLEU_BP = 1.0000
  => BLEU = 0.8068

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:756 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 17931 / 17931 = 1.0000
BLEU_precision(2) = 14421 / 17175 = 0.8397
BLEU_precision(3) = 12333 / 16420 = 0.7511
BLEU_precision(4) = 10504 / 15667 = 0.6705
BLEU_precision = 0.8064
Length of candidate corpus = 17931
Effective length of reference corpus = 17931
BLEU_BP = 1.0000
  => BLEU = 0.8064

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:766 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18085 / 18085 = 1.0000
BLEU_precision(2) = 14544 / 17319 = 0.8398
BLEU_precision(3) = 12439 / 16554 = 0.7514
BLEU_precision(4) = 10594 / 15791 = 0.6709
BLEU_precision = 0.8066
Length of candidate corpus = 18085
Effective length of reference corpus = 18085
BLEU_BP = 1.0000
  => BLEU = 0.8066

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:776 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18296 / 18296 = 1.0000
BLEU_precision(2) = 14717 / 17520 = 0.8400
BLEU_precision(3) = 12584 / 16745 = 0.7515
BLEU_precision(4) = 10714 / 15972 = 0.6708
BLEU_precision = 0.8067
Length of candidate corpus = 18296
Effective length of reference corpus = 18296
BLEU_BP = 1.0000
  => BLEU = 0.8067

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:786 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18472 / 18472 = 1.0000
BLEU_precision(2) = 14864 / 17686 = 0.8404
BLEU_precision(3) = 12710 / 16901 = 0.7520
BLEU_precision(4) = 10819 / 16118 = 0.6712
BLEU_precision = 0.8071
Length of candidate corpus = 18472
Effective length of reference corpus = 18472
BLEU_BP = 1.0000
  => BLEU = 0.8071

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:796 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18663 / 18663 = 1.0000
BLEU_precision(2) = 15015 / 17867 = 0.8404
BLEU_precision(3) = 12832 / 17072 = 0.7516
BLEU_precision(4) = 10917 / 16279 = 0.6706
BLEU_precision = 0.8068
Length of candidate corpus = 18663
Effective length of reference corpus = 18663
BLEU_BP = 1.0000
  => BLEU = 0.8068

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:806 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18870 / 18870 = 1.0000
BLEU_precision(2) = 15186 / 18064 = 0.8407
BLEU_precision(3) = 12975 / 17259 = 0.7518
BLEU_precision(4) = 11036 / 16456 = 0.6706
BLEU_precision = 0.8069
Length of candidate corpus = 18870
Effective length of reference corpus = 18870
BLEU_BP = 1.0000
  => BLEU = 0.8069

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:816 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19082 / 19082 = 1.0000
BLEU_precision(2) = 15358 / 18266 = 0.8408
BLEU_precision(3) = 13121 / 17451 = 0.7519
BLEU_precision(4) = 11156 / 16638 = 0.6705
BLEU_precision = 0.8069
Length of candidate corpus = 19082
Effective length of reference corpus = 19082
BLEU_BP = 1.0000
  => BLEU = 0.8069

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:826 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19250 / 19250 = 1.0000
BLEU_precision(2) = 15489 / 18424 = 0.8407
BLEU_precision(3) = 13228 / 17599 = 0.7516
BLEU_precision(4) = 11242 / 16776 = 0.6701
BLEU_precision = 0.8067
Length of candidate corpus = 19250
Effective length of reference corpus = 19250
BLEU_BP = 1.0000
  => BLEU = 0.8067

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:836 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19415 / 19415 = 1.0000
BLEU_precision(2) = 15605 / 18579 = 0.8399
BLEU_precision(3) = 13321 / 17744 = 0.7507
BLEU_precision(4) = 11314 / 16912 = 0.6690
BLEU_precision = 0.8059
Length of candidate corpus = 19415
Effective length of reference corpus = 19415
BLEU_BP = 1.0000
  => BLEU = 0.8059

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:846 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19572 / 19572 = 1.0000
BLEU_precision(2) = 15725 / 18726 = 0.8397
BLEU_precision(3) = 13420 / 17881 = 0.7505
BLEU_precision(4) = 11396 / 17039 = 0.6688
BLEU_precision = 0.8058
Length of candidate corpus = 19572
Effective length of reference corpus = 19572
BLEU_BP = 1.0000
  => BLEU = 0.8058

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:856 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19701 / 19701 = 1.0000
BLEU_precision(2) = 15827 / 18845 = 0.8399
BLEU_precision(3) = 13504 / 17990 = 0.7506
BLEU_precision(4) = 11464 / 17138 = 0.6689
BLEU_precision = 0.8058
Length of candidate corpus = 19701
Effective length of reference corpus = 19701
BLEU_BP = 1.0000
  => BLEU = 0.8058

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:866 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19852 / 19852 = 1.0000
BLEU_precision(2) = 15937 / 18986 = 0.8394
BLEU_precision(3) = 13598 / 18121 = 0.7504
BLEU_precision(4) = 11546 / 17259 = 0.6690
BLEU_precision = 0.8057
Length of candidate corpus = 19852
Effective length of reference corpus = 19852
BLEU_BP = 1.0000
  => BLEU = 0.8057

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:876 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20066 / 20066 = 1.0000
BLEU_precision(2) = 16106 / 19190 = 0.8393
BLEU_precision(3) = 13745 / 18315 = 0.7505
BLEU_precision(4) = 11679 / 17443 = 0.6696
BLEU_precision = 0.8059
Length of candidate corpus = 20066
Effective length of reference corpus = 20066
BLEU_BP = 1.0000
  => BLEU = 0.8059

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:886 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20255 / 20255 = 1.0000
BLEU_precision(2) = 16243 / 19369 = 0.8386
BLEU_precision(3) = 13854 / 18484 = 0.7495
BLEU_precision(4) = 11764 / 17602 = 0.6683
BLEU_precision = 0.8051
Length of candidate corpus = 20255
Effective length of reference corpus = 20255
BLEU_BP = 1.0000
  => BLEU = 0.8051

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:896 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20467 / 20467 = 1.0000
BLEU_precision(2) = 16410 / 19571 = 0.8385
BLEU_precision(3) = 13990 / 18676 = 0.7491
BLEU_precision(4) = 11872 / 17784 = 0.6676
BLEU_precision = 0.8047
Length of candidate corpus = 20467
Effective length of reference corpus = 20467
BLEU_BP = 1.0000
  => BLEU = 0.8047

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:906 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20528 / 20528 = 1.0000
BLEU_precision(2) = 16451 / 19622 = 0.8384
BLEU_precision(3) = 14021 / 18718 = 0.7491
BLEU_precision(4) = 11893 / 17817 = 0.6675
BLEU_precision = 0.8046
Length of candidate corpus = 20528
Effective length of reference corpus = 20528
BLEU_BP = 1.0000
  => BLEU = 0.8046

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:916 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20723 / 20723 = 1.0000
BLEU_precision(2) = 16598 / 19807 = 0.8380
BLEU_precision(3) = 14142 / 18893 = 0.7485
BLEU_precision(4) = 11989 / 17982 = 0.6667
BLEU_precision = 0.8042
Length of candidate corpus = 20723
Effective length of reference corpus = 20723
BLEU_BP = 1.0000
  => BLEU = 0.8042

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:926 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20979 / 20979 = 1.0000
BLEU_precision(2) = 16818 / 20053 = 0.8387
BLEU_precision(3) = 14338 / 19129 = 0.7495
BLEU_precision(4) = 12163 / 18208 = 0.6680
BLEU_precision = 0.8050
Length of candidate corpus = 20979
Effective length of reference corpus = 20979
BLEU_BP = 1.0000
  => BLEU = 0.8050

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:936 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 21257 / 21257 = 1.0000
BLEU_precision(2) = 17043 / 20321 = 0.8387
BLEU_precision(3) = 14527 / 19387 = 0.7493
BLEU_precision(4) = 12318 / 18456 = 0.6674
BLEU_precision = 0.8048
Length of candidate corpus = 21257
Effective length of reference corpus = 21257
BLEU_BP = 1.0000
  => BLEU = 0.8048

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:946 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 21490 / 21490 = 1.0000
BLEU_precision(2) = 17234 / 20544 = 0.8389
BLEU_precision(3) = 14691 / 19600 = 0.7495
BLEU_precision(4) = 12458 / 18659 = 0.6677
BLEU_precision = 0.8049
Length of candidate corpus = 21490
Effective length of reference corpus = 21490
BLEU_BP = 1.0000
  => BLEU = 0.8049

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:956 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 21812 / 21812 = 1.0000
BLEU_precision(2) = 17493 / 20856 = 0.8388
BLEU_precision(3) = 14911 / 19902 = 0.7492
BLEU_precision(4) = 12641 / 18951 = 0.6670
BLEU_precision = 0.8046
Length of candidate corpus = 21812
Effective length of reference corpus = 21812
BLEU_BP = 1.0000
  => BLEU = 0.8046

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:966 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 22019 / 22019 = 1.0000
BLEU_precision(2) = 17662 / 21053 = 0.8389
BLEU_precision(3) = 15055 / 20089 = 0.7494
BLEU_precision(4) = 12763 / 19128 = 0.6672
BLEU_precision = 0.8048
Length of candidate corpus = 22019
Effective length of reference corpus = 22019
BLEU_BP = 1.0000
  => BLEU = 0.8048

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:976 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 22203 / 22203 = 1.0000
BLEU_precision(2) = 17826 / 21227 = 0.8398
BLEU_precision(3) = 15203 / 20253 = 0.7507
BLEU_precision(4) = 12898 / 19282 = 0.6689
BLEU_precision = 0.8058
Length of candidate corpus = 22203
Effective length of reference corpus = 22203
BLEU_BP = 1.0000
  => BLEU = 0.8058

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:986 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 22387 / 22387 = 1.0000
BLEU_precision(2) = 17966 / 21401 = 0.8395
BLEU_precision(3) = 15319 / 20417 = 0.7503
BLEU_precision(4) = 12993 / 19436 = 0.6685
BLEU_precision = 0.8055
Length of candidate corpus = 22387
Effective length of reference corpus = 22387
BLEU_BP = 1.0000
  => BLEU = 0.8055

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:996 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 22589 / 22589 = 1.0000
BLEU_precision(2) = 18124 / 21593 = 0.8393
BLEU_precision(3) = 15451 / 20599 = 0.7501
BLEU_precision(4) = 13102 / 19608 = 0.6682
BLEU_precision = 0.8054
Length of candidate corpus = 22589
Effective length of reference corpus = 22589
BLEU_BP = 1.0000
  => BLEU = 0.8054

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9317 / 12293 = 0.7579
BLEU_precision(3) = 7292 / 11768 = 0.6196
BLEU_precision(4) = 5611 / 11244 = 0.4990
BLEU_precision = 0.6958
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6958

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:536 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13023 / 13023 = 1.0000
BLEU_precision(2) = 9473 / 12487 = 0.7586
BLEU_precision(3) = 7413 / 11952 = 0.6202
BLEU_precision(4) = 5704 / 11418 = 0.4996
BLEU_precision = 0.6963
Length of candidate corpus = 13023
Effective length of reference corpus = 13023
BLEU_BP = 1.0000
  => BLEU = 0.6963

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:546 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13263 / 13263 = 1.0000
BLEU_precision(2) = 9644 / 12717 = 0.7584
BLEU_precision(3) = 7540 / 12172 = 0.6195
BLEU_precision(4) = 5796 / 11628 = 0.4985
BLEU_precision = 0.6956
Length of candidate corpus = 13263
Effective length of reference corpus = 13263
BLEU_BP = 1.0000
  => BLEU = 0.6956

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:556 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13469 / 13469 = 1.0000
BLEU_precision(2) = 9804 / 12913 = 0.7592
BLEU_precision(3) = 7668 / 12358 = 0.6205
BLEU_precision(4) = 5895 / 11804 = 0.4994
BLEU_precision = 0.6965
Length of candidate corpus = 13469
Effective length of reference corpus = 13469
BLEU_BP = 1.0000
  => BLEU = 0.6965

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:566 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13702 / 13702 = 1.0000
BLEU_precision(2) = 9966 / 13136 = 0.7587
BLEU_precision(3) = 7785 / 12571 = 0.6193
BLEU_precision(4) = 5978 / 12007 = 0.4979
BLEU_precision = 0.6955
Length of candidate corpus = 13702
Effective length of reference corpus = 13702
BLEU_BP = 1.0000
  => BLEU = 0.6955

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:576 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 13891 / 13891 = 1.0000
BLEU_precision(2) = 10083 / 13315 = 0.7573
BLEU_precision(3) = 7863 / 12740 = 0.6172
BLEU_precision(4) = 6028 / 12166 = 0.4955
BLEU_precision = 0.6937
Length of candidate corpus = 13891
Effective length of reference corpus = 13891
BLEU_BP = 1.0000
  => BLEU = 0.6937

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:586 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 14130 / 14130 = 1.0000
BLEU_precision(2) = 10243 / 13544 = 0.7563
BLEU_precision(3) = 7981 / 12959 = 0.6159
BLEU_precision(4) = 6118 / 12375 = 0.4944
BLEU_precision = 0.6927
Length of candidate corpus = 14130
Effective length of reference corpus = 14130
BLEU_BP = 1.0000
  => BLEU = 0.6927

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:596 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 14342 / 14342 = 1.0000
BLEU_precision(2) = 10377 / 13746 = 0.7549
BLEU_precision(3) = 8070 / 13151 = 0.6136
BLEU_precision(4) = 6175 / 12557 = 0.4918
BLEU_precision = 0.6909
Length of candidate corpus = 14342
Effective length of reference corpus = 14342
BLEU_BP = 1.0000
  => BLEU = 0.6909

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:606 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 14593 / 14593 = 1.0000
BLEU_precision(2) = 10548 / 13987 = 0.7541
BLEU_precision(3) = 8196 / 13382 = 0.6125
BLEU_precision(4) = 6268 / 12778 = 0.4905
BLEU_precision = 0.6899
Length of candidate corpus = 14593
Effective length of reference corpus = 14593
BLEU_BP = 1.0000
  => BLEU = 0.6899

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:616 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 14847 / 14847 = 1.0000
BLEU_precision(2) = 10725 / 14231 = 0.7536
BLEU_precision(3) = 8330 / 13616 = 0.6118
BLEU_precision(4) = 6370 / 13002 = 0.4899
BLEU_precision = 0.6894
Length of candidate corpus = 14847
Effective length of reference corpus = 14847
BLEU_BP = 1.0000
  => BLEU = 0.6894

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:626 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15072 / 15072 = 1.0000
BLEU_precision(2) = 10876 / 14446 = 0.7529
BLEU_precision(3) = 8446 / 13821 = 0.6111
BLEU_precision(4) = 6460 / 13197 = 0.4895
BLEU_precision = 0.6889
Length of candidate corpus = 15072
Effective length of reference corpus = 15072
BLEU_BP = 1.0000
  => BLEU = 0.6889

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:636 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15277 / 15277 = 1.0000
BLEU_precision(2) = 11013 / 14641 = 0.7522
BLEU_precision(3) = 8547 / 14006 = 0.6102
BLEU_precision(4) = 6532 / 13372 = 0.4885
BLEU_precision = 0.6881
Length of candidate corpus = 15277
Effective length of reference corpus = 15277
BLEU_BP = 1.0000
  => BLEU = 0.6881

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:646 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15471 / 15471 = 1.0000
BLEU_precision(2) = 11143 / 14825 = 0.7516
BLEU_precision(3) = 8638 / 14180 = 0.6092
BLEU_precision(4) = 6597 / 13536 = 0.4874
BLEU_precision = 0.6873
Length of candidate corpus = 15471
Effective length of reference corpus = 15471
BLEU_BP = 1.0000
  => BLEU = 0.6873

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:656 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15642 / 15642 = 1.0000
BLEU_precision(2) = 11256 / 14986 = 0.7511
BLEU_precision(3) = 8719 / 14331 = 0.6084
BLEU_precision(4) = 6656 / 13678 = 0.4866
BLEU_precision = 0.6867
Length of candidate corpus = 15642
Effective length of reference corpus = 15642
BLEU_BP = 1.0000
  => BLEU = 0.6867

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:666 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 15854 / 15854 = 1.0000
BLEU_precision(2) = 11382 / 15188 = 0.7494
BLEU_precision(3) = 8805 / 14523 = 0.6063
BLEU_precision(4) = 6713 / 13860 = 0.4843
BLEU_precision = 0.6849
Length of candidate corpus = 15854
Effective length of reference corpus = 15854
BLEU_BP = 1.0000
  => BLEU = 0.6849

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:676 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16083 / 16083 = 1.0000
BLEU_precision(2) = 11539 / 15407 = 0.7489
BLEU_precision(3) = 8926 / 14732 = 0.6059
BLEU_precision(4) = 6809 / 14059 = 0.4843
BLEU_precision = 0.6847
Length of candidate corpus = 16083
Effective length of reference corpus = 16083
BLEU_BP = 1.0000
  => BLEU = 0.6847

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:686 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16243 / 16243 = 1.0000
BLEU_precision(2) = 11646 / 15557 = 0.7486
BLEU_precision(3) = 9002 / 14872 = 0.6053
BLEU_precision(4) = 6862 / 14189 = 0.4836
BLEU_precision = 0.6842
Length of candidate corpus = 16243
Effective length of reference corpus = 16243
BLEU_BP = 1.0000
  => BLEU = 0.6842

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:696 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16506 / 16506 = 1.0000
BLEU_precision(2) = 11840 / 15810 = 0.7489
BLEU_precision(3) = 9151 / 15115 = 0.6054
BLEU_precision(4) = 6975 / 14422 = 0.4836
BLEU_precision = 0.6843
Length of candidate corpus = 16506
Effective length of reference corpus = 16506
BLEU_BP = 1.0000
  => BLEU = 0.6843

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:706 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16714 / 16714 = 1.0000
BLEU_precision(2) = 11972 / 16008 = 0.7479
BLEU_precision(3) = 9244 / 15303 = 0.6041
BLEU_precision(4) = 7034 / 14600 = 0.4818
BLEU_precision = 0.6830
Length of candidate corpus = 16714
Effective length of reference corpus = 16714
BLEU_BP = 1.0000
  => BLEU = 0.6830

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:716 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 16985 / 16985 = 1.0000
BLEU_precision(2) = 12158 / 16269 = 0.7473
BLEU_precision(3) = 9374 / 15554 = 0.6027
BLEU_precision(4) = 7119 / 14841 = 0.4797
BLEU_precision = 0.6818
Length of candidate corpus = 16985
Effective length of reference corpus = 16985
BLEU_BP = 1.0000
  => BLEU = 0.6818

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:726 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 17222 / 17222 = 1.0000
BLEU_precision(2) = 12327 / 16496 = 0.7473
BLEU_precision(3) = 9508 / 15771 = 0.6029
BLEU_precision(4) = 7220 / 15048 = 0.4798
BLEU_precision = 0.6819
Length of candidate corpus = 17222
Effective length of reference corpus = 17222
BLEU_BP = 1.0000
  => BLEU = 0.6819

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:736 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 17462 / 17462 = 1.0000
BLEU_precision(2) = 12514 / 16726 = 0.7482
BLEU_precision(3) = 9659 / 15991 = 0.6040
BLEU_precision(4) = 7340 / 15258 = 0.4811
BLEU_precision = 0.6828
Length of candidate corpus = 17462
Effective length of reference corpus = 17462
BLEU_BP = 1.0000
  => BLEU = 0.6828

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:746 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 17718 / 17718 = 1.0000
BLEU_precision(2) = 12689 / 16972 = 0.7476
BLEU_precision(3) = 9790 / 16227 = 0.6033
BLEU_precision(4) = 7437 / 15484 = 0.4803
BLEU_precision = 0.6822
Length of candidate corpus = 17718
Effective length of reference corpus = 17718
BLEU_BP = 1.0000
  => BLEU = 0.6822

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:756 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 17931 / 17931 = 1.0000
BLEU_precision(2) = 12828 / 17175 = 0.7469
BLEU_precision(3) = 9883 / 16420 = 0.6019
BLEU_precision(4) = 7496 / 15667 = 0.4785
BLEU_precision = 0.6810
Length of candidate corpus = 17931
Effective length of reference corpus = 17931
BLEU_BP = 1.0000
  => BLEU = 0.6810

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:766 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18085 / 18085 = 1.0000
BLEU_precision(2) = 12928 / 17319 = 0.7465
BLEU_precision(3) = 9955 / 16554 = 0.6014
BLEU_precision(4) = 7545 / 15791 = 0.4778
BLEU_precision = 0.6805
Length of candidate corpus = 18085
Effective length of reference corpus = 18085
BLEU_BP = 1.0000
  => BLEU = 0.6805

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:776 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18296 / 18296 = 1.0000
BLEU_precision(2) = 13087 / 17520 = 0.7470
BLEU_precision(3) = 10079 / 16745 = 0.6019
BLEU_precision(4) = 7641 / 15972 = 0.4784
BLEU_precision = 0.6810
Length of candidate corpus = 18296
Effective length of reference corpus = 18296
BLEU_BP = 1.0000
  => BLEU = 0.6810

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:786 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18472 / 18472 = 1.0000
BLEU_precision(2) = 13211 / 17686 = 0.7470
BLEU_precision(3) = 10172 / 16901 = 0.6019
BLEU_precision(4) = 7706 / 16118 = 0.4781
BLEU_precision = 0.6809
Length of candidate corpus = 18472
Effective length of reference corpus = 18472
BLEU_BP = 1.0000
  => BLEU = 0.6809

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:796 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18663 / 18663 = 1.0000
BLEU_precision(2) = 13347 / 17867 = 0.7470
BLEU_precision(3) = 10273 / 17072 = 0.6017
BLEU_precision(4) = 7778 / 16279 = 0.4778
BLEU_precision = 0.6808
Length of candidate corpus = 18663
Effective length of reference corpus = 18663
BLEU_BP = 1.0000
  => BLEU = 0.6808

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:806 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 18870 / 18870 = 1.0000
BLEU_precision(2) = 13501 / 18064 = 0.7474
BLEU_precision(3) = 10389 / 17259 = 0.6019
BLEU_precision(4) = 7865 / 16456 = 0.4779
BLEU_precision = 0.6810
Length of candidate corpus = 18870
Effective length of reference corpus = 18870
BLEU_BP = 1.0000
  => BLEU = 0.6810

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:816 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19082 / 19082 = 1.0000
BLEU_precision(2) = 13661 / 18266 = 0.7479
BLEU_precision(3) = 10516 / 17451 = 0.6026
BLEU_precision(4) = 7963 / 16638 = 0.4786
BLEU_precision = 0.6815
Length of candidate corpus = 19082
Effective length of reference corpus = 19082
BLEU_BP = 1.0000
  => BLEU = 0.6815

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:826 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19250 / 19250 = 1.0000
BLEU_precision(2) = 13780 / 18424 = 0.7479
BLEU_precision(3) = 10605 / 17599 = 0.6026
BLEU_precision(4) = 8026 / 16776 = 0.4784
BLEU_precision = 0.6814
Length of candidate corpus = 19250
Effective length of reference corpus = 19250
BLEU_BP = 1.0000
  => BLEU = 0.6814

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:836 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19415 / 19415 = 1.0000
BLEU_precision(2) = 13882 / 18579 = 0.7472
BLEU_precision(3) = 10676 / 17744 = 0.6017
BLEU_precision(4) = 8071 / 16912 = 0.4772
BLEU_precision = 0.6806
Length of candidate corpus = 19415
Effective length of reference corpus = 19415
BLEU_BP = 1.0000
  => BLEU = 0.6806

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:846 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19572 / 19572 = 1.0000
BLEU_precision(2) = 13987 / 18726 = 0.7469
BLEU_precision(3) = 10754 / 17881 = 0.6014
BLEU_precision(4) = 8130 / 17039 = 0.4771
BLEU_precision = 0.6804
Length of candidate corpus = 19572
Effective length of reference corpus = 19572
BLEU_BP = 1.0000
  => BLEU = 0.6804

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:856 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19701 / 19701 = 1.0000
BLEU_precision(2) = 14075 / 18845 = 0.7469
BLEU_precision(3) = 10817 / 17990 = 0.6013
BLEU_precision(4) = 8175 / 17138 = 0.4770
BLEU_precision = 0.6803
Length of candidate corpus = 19701
Effective length of reference corpus = 19701
BLEU_BP = 1.0000
  => BLEU = 0.6803

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:866 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 19852 / 19852 = 1.0000
BLEU_precision(2) = 14176 / 18986 = 0.7467
BLEU_precision(3) = 10893 / 18121 = 0.6011
BLEU_precision(4) = 8233 / 17259 = 0.4770
BLEU_precision = 0.6802
Length of candidate corpus = 19852
Effective length of reference corpus = 19852
BLEU_BP = 1.0000
  => BLEU = 0.6802

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:876 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20066 / 20066 = 1.0000
BLEU_precision(2) = 14320 / 19190 = 0.7462
BLEU_precision(3) = 11003 / 18315 = 0.6008
BLEU_precision(4) = 8321 / 17443 = 0.4770
BLEU_precision = 0.6800
Length of candidate corpus = 20066
Effective length of reference corpus = 20066
BLEU_BP = 1.0000
  => BLEU = 0.6800

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:886 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20255 / 20255 = 1.0000
BLEU_precision(2) = 14445 / 19369 = 0.7458
BLEU_precision(3) = 11092 / 18484 = 0.6001
BLEU_precision(4) = 8378 / 17602 = 0.4760
BLEU_precision = 0.6794
Length of candidate corpus = 20255
Effective length of reference corpus = 20255
BLEU_BP = 1.0000
  => BLEU = 0.6794

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:896 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20467 / 20467 = 1.0000
BLEU_precision(2) = 14588 / 19571 = 0.7454
BLEU_precision(3) = 11196 / 18676 = 0.5995
BLEU_precision(4) = 8450 / 17784 = 0.4751
BLEU_precision = 0.6788
Length of candidate corpus = 20467
Effective length of reference corpus = 20467
BLEU_BP = 1.0000
  => BLEU = 0.6788

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:906 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20528 / 20528 = 1.0000
BLEU_precision(2) = 14622 / 19622 = 0.7452
BLEU_precision(3) = 11217 / 18718 = 0.5993
BLEU_precision(4) = 8463 / 17817 = 0.4750
BLEU_precision = 0.6786
Length of candidate corpus = 20528
Effective length of reference corpus = 20528
BLEU_BP = 1.0000
  => BLEU = 0.6786

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:916 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20723 / 20723 = 1.0000
BLEU_precision(2) = 14766 / 19807 = 0.7455
BLEU_precision(3) = 11329 / 18893 = 0.5996
BLEU_precision(4) = 8546 / 17982 = 0.4753
BLEU_precision = 0.6789
Length of candidate corpus = 20723
Effective length of reference corpus = 20723
BLEU_BP = 1.0000
  => BLEU = 0.6789

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:926 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 20979 / 20979 = 1.0000
BLEU_precision(2) = 14955 / 20053 = 0.7458
BLEU_precision(3) = 11474 / 19129 = 0.5998
BLEU_precision(4) = 8658 / 18208 = 0.4755
BLEU_precision = 0.6791
Length of candidate corpus = 20979
Effective length of reference corpus = 20979
BLEU_BP = 1.0000
  => BLEU = 0.6791

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:936 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 21257 / 21257 = 1.0000
BLEU_precision(2) = 15148 / 20321 = 0.7454
BLEU_precision(3) = 11613 / 19387 = 0.5990
BLEU_precision(4) = 8751 / 18456 = 0.4742
BLEU_precision = 0.6783
Length of candidate corpus = 21257
Effective length of reference corpus = 21257
BLEU_BP = 1.0000
  => BLEU = 0.6783

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:946 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 21490 / 21490 = 1.0000
BLEU_precision(2) = 15324 / 20544 = 0.7459
BLEU_precision(3) = 11751 / 19600 = 0.5995
BLEU_precision(4) = 8857 / 18659 = 0.4747
BLEU_precision = 0.6788
Length of candidate corpus = 21490
Effective length of reference corpus = 21490
BLEU_BP = 1.0000
  => BLEU = 0.6788

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:956 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 21812 / 21812 = 1.0000
BLEU_precision(2) = 15555 / 20856 = 0.7458
BLEU_precision(3) = 11923 / 19902 = 0.5991
BLEU_precision(4) = 8978 / 18951 = 0.4737
BLEU_precision = 0.6783
Length of candidate corpus = 21812
Effective length of reference corpus = 21812
BLEU_BP = 1.0000
  => BLEU = 0.6783

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:966 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 22019 / 22019 = 1.0000
BLEU_precision(2) = 15711 / 21053 = 0.7463
BLEU_precision(3) = 12051 / 20089 = 0.5999
BLEU_precision(4) = 9084 / 19128 = 0.4749
BLEU_precision = 0.6790
Length of candidate corpus = 22019
Effective length of reference corpus = 22019
BLEU_BP = 1.0000
  => BLEU = 0.6790

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:976 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 22203 / 22203 = 1.0000
BLEU_precision(2) = 15865 / 21227 = 0.7474
BLEU_precision(3) = 12181 / 20253 = 0.6014
BLEU_precision(4) = 9195 / 19282 = 0.4769
BLEU_precision = 0.6804
Length of candidate corpus = 22203
Effective length of reference corpus = 22203
BLEU_BP = 1.0000
  => BLEU = 0.6804

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:986 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 22387 / 22387 = 1.0000
BLEU_precision(2) = 15985 / 21401 = 0.7469
BLEU_precision(3) = 12268 / 20417 = 0.6009
BLEU_precision(4) = 9256 / 19436 = 0.4762
BLEU_precision = 0.6799
Length of candidate corpus = 22387
Effective length of reference corpus = 22387
BLEU_BP = 1.0000
  => BLEU = 0.6799

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:996 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 22589 / 22589 = 1.0000
BLEU_precision(2) = 16126 / 21593 = 0.7468
BLEU_precision(3) = 12377 / 20599 = 0.6009
BLEU_precision(4) = 9339 / 19608 = 0.4763
BLEU_precision = 0.6799
Length of candidate corpus = 22589
Effective length of reference corpus = 22589
BLEU_BP = 1.0000
  => BLEU = 0.6799

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.2081748112861263E11]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10283 / 12293 = 0.8365
BLEU_precision(3) = 8754 / 11768 = 0.7439
BLEU_precision(4) = 7437 / 11244 = 0.6614
BLEU_precision = 0.8010
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8010

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,0.2,1.1035576506337094E14]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10408 / 12293 = 0.8467
BLEU_precision(3) = 8977 / 11768 = 0.7628
BLEU_precision(4) = 7711 / 11244 = 0.6858
BLEU_precision = 0.8158
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8158

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
=> Optimizing Lambda: [0.1,-0.415668497636675,-0.1]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9317 / 12293 = 0.7579
BLEU_precision(3) = 7292 / 11768 = 0.6196
BLEU_precision(4) = 5611 / 11244 = 0.4990
BLEU_precision = 0.6958
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6958

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
Mean Optimal: true
=> Optimizing Lambda: [0.027034017423342754,1.3781151528452435E15,2.16922622796959E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10431 / 12293 = 0.8485
BLEU_precision(3) = 8966 / 11768 = 0.7619
BLEU_precision(4) = 7701 / 11244 = 0.6849
BLEU_precision = 0.8157
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8157

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
Mean Optimal: true
=> Optimizing Lambda: [0.10634238705240086,2.0009103630428118E12,1.9454333883344635E15]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10454 / 12293 = 0.8504
BLEU_precision(3) = 9035 / 11768 = 0.7678
BLEU_precision(4) = 7791 / 11244 = 0.6929
BLEU_precision = 0.8201
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8201

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
Mean Optimal: true
=> Optimizing Lambda: [0.13304805362235392,-4277.99232306145,0.020745416904829988]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9162 / 12293 = 0.7453
BLEU_precision(3) = 7053 / 11768 = 0.5993
BLEU_precision(4) = 5314 / 11244 = 0.4726
BLEU_precision = 0.6778
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.6778

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
Mean Optimal: false
=> Optimizing Lambda: [0.1,0.2,2.7253109831386456E14]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10420 / 12293 = 0.8476
BLEU_precision(3) = 9005 / 11768 = 0.7652
BLEU_precision(4) = 7774 / 11244 = 0.6914
BLEU_precision = 0.8183
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8183

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
Mean Optimal: false
=> Optimizing Lambda: [0.04975277907319677,0.2,6.915585479814105E13]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10503 / 12293 = 0.8544
BLEU_precision(3) = 9154 / 11768 = 0.7779
BLEU_precision(4) = 7957 / 11244 = 0.7077
BLEU_precision = 0.8281
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8281

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
Mean Optimal: false
=> Optimizing Lambda: [0.1,-0.584560089096255,-0.1]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9351 / 12293 = 0.7607
BLEU_precision(3) = 7360 / 11768 = 0.6254
BLEU_precision(4) = 5707 / 11244 = 0.5076
BLEU_precision = 0.7010
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7010

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Kneser-ney Smoothing
Pre/Post sept: 0.7
Mean Optimal: false
=> Optimizing Lambda: [0.1,0.2,5.818460721911569E10]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10356 / 12293 = 0.8424
BLEU_precision(3) = 8893 / 11768 = 0.7557
BLEU_precision(4) = 7627 / 11244 = 0.6783
BLEU_precision = 0.8106
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8106

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Add one Smoothing
Pre/Post sept: 0.7
Mean Optimal: false
=> Optimizing Lambda: [0.1,0.2,2.6649994582757225E14]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 10512 / 12293 = 0.8551
BLEU_precision(3) = 9166 / 11768 = 0.7789
BLEU_precision(4) = 7970 / 11244 = 0.7088
BLEU_precision = 0.8289
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.8289

 
	========================================================
train:499 sentences
NGRAM SMOOTH Method: Modified Kneser-ney Smothing by Kylm
Pre/Post sept: 0.7
Mean Optimal: false
=> Optimizing Lambda: [-0.017230818545013626,0.2,-0.1]
test:526 sentences
=> Bleu Summary:
Evaluating set of 1'th candidate realization ...
BLEU_precision(1) = 12819 / 12819 = 1.0000
BLEU_precision(2) = 9417 / 12293 = 0.7660
BLEU_precision(3) = 7350 / 11768 = 0.6246
BLEU_precision(4) = 5654 / 11244 = 0.5028
BLEU_precision = 0.7004
Length of candidate corpus = 12819
Effective length of reference corpus = 12819
BLEU_BP = 1.0000
  => BLEU = 0.7004

 
	========================================================
